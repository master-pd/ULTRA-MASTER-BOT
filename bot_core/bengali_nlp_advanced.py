"""
üáßüá© BENGALI NLP ADVANCED
Advanced Bengali Language Processing
"""

import re
import json
import random
from typing import List, Dict, Tuple
import numpy as np
from collections import defaultdict

class BengaliNLP:
    def __init__(self):
        self.bengali_stopwords = self.load_bengali_stopwords()
        self.sentiment_words = self.load_sentiment_words()
        self.response_patterns = self.load_response_patterns()
        
    def load_bengali_stopwords(self):
        """Load Bengali stopwords"""
        return {
            '‡¶è‡¶¨‡¶Ç', '‡¶Ü‡¶∞', '‡¶ì', '‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ', '‡¶Ø‡ßá', '‡¶Ø‡¶ø‡¶®‡¶ø', '‡¶Ø‡¶æ‡¶∞‡¶æ', '‡¶Ø‡¶æ‡¶∞', '‡¶§‡¶æ', '‡¶§‡¶æ‡¶á', 
            '‡¶§‡¶ø‡¶®‡¶ø', '‡¶§‡ßÅ‡¶Æ‡¶ø', '‡¶§‡ßã‡¶Æ‡¶æ‡¶∞', '‡¶§‡¶æ‡¶∞‡¶æ', '‡¶§‡¶æ‡¶∞', '‡¶è‡¶á', '‡¶è‡¶ï‡¶ü‡¶ø', '‡¶è‡¶ï', '‡¶ï‡¶ø', '‡¶ï‡ßÄ',
            '‡¶ï‡ßá‡¶®', '‡¶ï‡ßã‡¶•‡¶æ‡¶Ø‡¶º', '‡¶ï‡¶ñ‡¶®', '‡¶ï‡ßá‡¶Æ‡¶®', '‡¶ï‡ßá', '‡¶ï‡¶æ‡¶â‡¶ï‡ßá', '‡¶ï‡¶ø‡¶õ‡ßÅ', '‡¶∏‡¶¨', '‡¶∏‡ßá‡¶ü‡¶æ',
            '‡¶π‡¶Ø‡¶º', '‡¶π‡¶ö‡ßç‡¶õ‡ßá', '‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá', '‡¶π‡¶¨‡ßá‡¶®', '‡¶®‡ßá‡¶á', '‡¶®‡¶æ', '‡¶®‡¶Ø‡¶º', '‡¶π‡¶¨‡ßá', '‡¶π‡¶§‡ßã'
        }
    
    def load_sentiment_words(self):
        """Load sentiment words"""
        return {
            "positive": {
                "bn": ["‡¶≠‡¶æ‡¶≤", "‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞", "‡¶ö‡¶Æ‡ßé‡¶ï‡¶æ‡¶∞", "‡¶¨‡ßá‡¶∂", "‡¶Æ‡¶ú‡¶æ", "‡¶ñ‡ßÅ‡¶∂‡¶ø", "‡¶Ü‡¶®‡¶®‡ßç‡¶¶", "‡¶™‡ßç‡¶∞‡¶∂‡¶Ç‡¶∏‡¶æ"],
                "en": ["good", "nice", "excellent", "great", "happy", "joy", "praise"]
            },
            "negative": {
                "bn": ["‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™", "‡¶Æ‡¶®‡ßç‡¶¶", "‡¶Ö‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞", "‡¶¨‡¶æ‡¶ú‡ßá", "‡¶¶‡ßÅ‡¶É‡¶ñ", "‡¶ï‡¶∑‡ßç‡¶ü", "‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ"],
                "en": ["bad", "poor", "ugly", "sad", "pain", "problem"]
            },
            "neutral": {
                "bn": ["‡¶†‡¶ø‡¶ï", "‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£", "‡¶Æ‡ßã‡¶ü‡¶æ‡¶Æ‡ßÅ‡¶ü‡¶ø", "‡¶π‡¶≤", "‡¶π‡¶Ø‡¶º"],
                "en": ["ok", "normal", "average", "is", "am"]
            }
        }
    
    def load_response_patterns(self):
        """Load response patterns"""
        return {
            "greeting": {
                "bn": [
                    "‡¶π‡ßç‡¶Ø‡¶æ‡¶≤‡ßã! ‡¶Ü‡¶Æ‡¶ø MASTER ü™ì, ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ AI ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶ï‡•§",
                    "‡¶®‡¶Æ‡¶∏‡ßç‡¶ï‡¶æ‡¶∞! ‡¶ï‡ßá‡¶Æ‡¶® ‡¶Ü‡¶õ‡ßá‡¶®?",
                    "‡¶Ü‡¶∏‡¶∏‡¶æ‡¶≤‡¶æ‡¶Æ‡ßÅ ‡¶Ü‡¶≤‡¶æ‡¶á‡¶ï‡ßÅ‡¶Æ! ‡¶Ü‡¶Æ‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶Ü‡¶õ‡¶ø‡•§"
                ],
                "en": [
                    "Hello! I'm MASTER ü™ì, your AI assistant.",
                    "Hi there! How can I help you today?",
                    "Greetings! I'm here to assist you."
                ]
            },
            "question": {
                "bn": [
                    "‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶ú‡¶æ‡¶®‡¶§‡ßá ‡¶ö‡¶æ‡¶® {} ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡ßá?",
                    "{} - ‡¶è‡¶ü‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶≠‡¶æ‡¶≤ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡•§",
                    "‡¶Ü‡¶Æ‡¶ø {} ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡ßá ‡¶§‡¶•‡ßç‡¶Ø ‡¶¶‡¶ø‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø‡•§"
                ],
                "en": [
                    "Do you want to know about {}?",
                    "{} - that's a good question.",
                    "I can provide information about {}."
                ]
            },
            "thanks": {
                "bn": [
                    "‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá‡¶ì ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶!",
                    "‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶®‡¶æ, ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡ßá‡¶∞‡ßá ‡¶≠‡¶æ‡¶≤‡ßã ‡¶≤‡¶æ‡¶ó‡¶≤‡ßã‡•§",
                    "‡¶Ü‡¶∞‡¶ì ‡¶ï‡ßã‡¶®‡ßã ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶≤‡¶æ‡¶ó‡¶≤‡ßá ‡¶ú‡¶æ‡¶®‡¶æ‡¶¨‡ßá‡¶®‡•§"
                ],
                "en": [
                    "You're welcome!",
                    "No problem, happy to help!",
                    "Let me know if you need anything else."
                ]
            },
            "unknown": {
                "bn": [
                    "‡¶¶‡ßÅ‡¶É‡¶ñ‡¶ø‡¶§, ‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶ñ‡¶®‡ßã ‡¶è‡¶ü‡¶ø ‡¶∂‡¶ø‡¶ñ‡¶ø‡¶®‡¶ø‡•§",
                    "‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶á ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡ßá‡¶∞ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶è‡¶ñ‡¶®‡ßã ‡¶ú‡¶æ‡¶®‡¶ø ‡¶®‡¶æ‡•§",
                    "‡¶è‡¶ü‡¶ø ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡ßá ‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶ñ‡¶®‡ßã ‡¶∂‡¶ø‡¶ñ‡¶ø‡¶®‡¶ø, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶∂‡¶ø‡¶ñ‡¶¨‡ßã!"
                ],
                "en": [
                    "Sorry, I haven't learned that yet.",
                    "I don't know the answer to that question yet.",
                    "I haven't learned about that yet, but I will!"
                ]
            }
        }
    
    def detect_language(self, text: str) -> str:
        """Detect if text is Bengali or English"""
        # Count Bengali characters
        bengali_pattern = re.compile(r'[\u0980-\u09FF]')
        bengali_count = len(bengali_pattern.findall(text))
        
        # Count English characters
        english_pattern = re.compile(r'[a-zA-Z]')
        english_count = len(english_pattern.findall(text))
        
        if bengali_count > english_count:
            return "bengali"
        elif english_count > bengali_count:
            return "english"
        else:
            return "mixed"
    
    def extract_keywords_bengali(self, text: str) -> List[str]:
        """Extract keywords from Bengali text"""
        # Remove punctuation
        text = re.sub(r'[^\u0980-\u09FF\s]', '', text)
        
        # Split into words
        words = text.split()
        
        # Remove stopwords
        keywords = [word for word in words 
                   if word not in self.bengali_stopwords and len(word) > 1]
        
        # Remove duplicates but preserve order
        seen = set()
        unique_keywords = []
        for word in keywords:
            if word not in seen:
                seen.add(word)
                unique_keywords.append(word)
        
        return unique_keywords[:10]  # Return top 10 keywords
    
    def extract_keywords_english(self, text: str) -> List[str]:
        """Extract keywords from English text"""
        # Convert to lowercase and remove punctuation
        text = re.sub(r'[^\w\s]', '', text.lower())
        
        # Split into words
        words = text.split()
        
        # Simple English stopwords
        english_stopwords = {
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to',
            'for', 'of', 'with', 'by', 'is', 'am', 'are', 'was', 'were',
            'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did',
            'will', 'would', 'shall', 'should', 'may', 'might', 'must', 'can', 'could'
        }
        
        # Remove stopwords
        keywords = [word for word in words 
                   if word not in english_stopwords and len(word) > 2]
        
        # Remove duplicates
        return list(set(keywords))[:10]
    
    def analyze_sentiment(self, text: str) -> str:
        """Analyze sentiment of text"""
        text_lower = text.lower()
        
        positive_count = 0
        negative_count = 0
        
        # Check Bengali positive words
        for word in self.sentiment_words["positive"]["bn"]:
            if word in text_lower:
                positive_count += 1
        
        # Check Bengali negative words
        for word in self.sentiment_words["negative"]["bn"]:
            if word in text_lower:
                negative_count += 1
        
        # Check English positive words
        for word in self.sentiment_words["positive"]["en"]:
            if word in text_lower:
                positive_count += 1
        
        # Check English negative words
        for word in self.sentiment_words["negative"]["en"]:
            if word in text_lower:
                negative_count += 1
        
        if positive_count > negative_count:
            return "positive"
        elif negative_count > positive_count:
            return "negative"
        else:
            return "neutral"
    
    def generate_response(self, message: str) -> str:
        """Generate intelligent response"""
        language = self.detect_language(message)
        sentiment = self.analyze_sentiment(message)
        
        # Extract intent
        if any(word in message.lower() for word in ["‡¶π‡ßç‡¶Ø‡¶æ‡¶≤‡ßã", "‡¶π‡¶æ‡¶á", "hello", "hi"]):
            intent = "greeting"
        elif any(word in message.lower() for word in ["‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶", "‡¶•‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï‡¶∏", "thank"]):
            intent = "thanks"
        elif "?" in message:
            intent = "question"
        else:
            intent = "unknown"
        
        # Get appropriate response pattern
        if intent in self.response_patterns:
            patterns = self.response_patterns[intent].get(language, 
                                                         self.response_patterns[intent]["en"])
            
            if intent == "question":
                # Extract main topic from question
                keywords = (self.extract_keywords_bengali(message) 
                           if language == "bengali" 
                           else self.extract_keywords_english(message))
                topic = keywords[0] if keywords else "‡¶è‡¶ü‡¶ø"
                
                # Format response with topic
                response = random.choice(patterns).format(topic)
            else:
                response = random.choice(patterns)
        else:
            response = random.choice(self.response_patterns["unknown"][language])
        
        # Add sentiment-based modifier
        if sentiment == "positive":
            modifiers = [" üòä", " üëç", " üéâ"]
            response += random.choice(modifiers)
        elif sentiment == "negative":
            modifiers = [" üòî", " ü§ó", " üí™"]
            response += random.choice(modifiers)
        
        return response
    
    def translate_bengali_to_english(self, text: str) -> str:
        """Simple Bengali to English translation (basic)"""
        # Basic word mapping
        translation_dict = {
            "‡¶π‡ßç‡¶Ø‡¶æ‡¶≤‡ßã": "Hello",
            "‡¶ï‡ßá‡¶Æ‡¶®": "how",
            "‡¶Ü‡¶õ‡ßá‡¶®": "are you",
            "‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶": "thank you",
            "‡¶®‡¶æ‡¶Æ": "name",
            "‡¶ï‡¶ø": "what",
            "‡¶ï‡ßá‡¶®": "why",
            "‡¶ï‡¶ñ‡¶®": "when",
            "‡¶ï‡ßã‡¶•‡¶æ‡¶Ø‡¶º": "where",
            "‡¶ï‡ßá": "who"
        }
        
        words = text.split()
        translated_words = []
        
        for word in words:
            if word in translation_dict:
                translated_words.append(translation_dict[word])
            else:
                translated_words.append(word)
        
        return " ".join(translated_words)
    
    def calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two texts"""
        # Simple Jaccard similarity
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 and not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union)
    
    def extract_named_entities(self, text: str) -> List[Dict]:
        """Extract named entities from text (simplified)"""
        entities = []
        
        # Patterns for different entity types
        patterns = {
            "name": r'(?:(?:‡¶∂‡ßç‡¶∞‡ßÄ|‡¶ú‡¶®‡¶æ‡¶¨|‡¶Æ‡¶ø‡¶∏‡ßç‡¶ü‡¶æ‡¶∞|‡¶Æ‡¶ø‡¶∏|‡¶Æ‡¶ø‡¶∏‡ßá‡¶∏)\s+)?([‡¶Ü-‡¶π]{2,})(?:\s+([‡¶Ü-‡¶π]{2,}))?',
            "location": r'([‡¶Ü-‡¶π]+(?:‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ|‡¶®‡¶ó‡¶∞|‡¶™‡ßÅ‡¶∞|‡¶¨‡¶æ‡¶¶|‡¶ñ‡¶æ‡¶≤‡¶ø|‡¶¨‡¶æ‡¶ú‡¶æ‡¶∞|‡¶∞‡ßã‡¶°|‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø‡¶ü))',
            "organization": r'([‡¶Ü-‡¶π]+(?:‡¶¨‡¶ø‡¶¶‡ßç‡¶Ø‡¶æ‡¶≤‡¶Ø‡¶º|‡¶ï‡¶≤‡ßá‡¶ú|‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶¨‡¶ø‡¶¶‡ßç‡¶Ø‡¶æ‡¶≤‡¶Ø‡¶º|‡¶ï‡ßã‡¶Æ‡ßç‡¶™‡¶æ‡¶®‡¶ø|‡¶≤‡¶ø‡¶Æ‡¶ø‡¶ü‡ßá‡¶°|‡¶ü‡ßç‡¶∞‡¶æ‡¶∏‡ßç‡¶ü))'
        }
        
        for entity_type, pattern in patterns.items():
            matches = re.finditer(pattern, text)
            for match in matches:
                entities.append({
                    "text": match.group(),
                    "type": entity_type,
                    "start": match.start(),
                    "end": match.end()
                })
        
        return entities